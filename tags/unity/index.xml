<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Unity | byung.org</title>
    <link>/tags/unity/</link>
      <atom:link href="/tags/unity/index.xml" rel="self" type="application/rss+xml" />
    <description>Unity</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>some copyrights; (2015)</copyright><lastBuildDate>Thu, 27 Dec 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Unity</title>
      <link>/tags/unity/</link>
    </image>
    
    <item>
      <title>Q-Learning Agent in VR</title>
      <link>/project/q-learning-vr/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/project/q-learning-vr/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;An AI agent is often not tangible. It’s an artificially being that usually resides in virtual space. We can seldom see robots and drones with AI on media, but not usually in the physical world. It’s very hard to bring agents to the physical world, but if we let them stay in their space, it becomes a lot easier to interact. The VR technologies let us be in a virtual space, thus we can experience the embodiment of an AI agent. This project is motivated by this gateway to space of another being.&lt;/p&gt;
&lt;h2 id=&#34;problem&#34;&gt;Problem&lt;/h2&gt;
&lt;p&gt;It’s very costly to bring AI to physical space, and it would cost a tremendous amount to develop and test such agent in physical space. But, if we are able to simulate good enough for AI agents, we believe that the cost of development can be reduced drastically. And, we believe the AI agent in VR can be very entertaining.&lt;/p&gt;
&lt;h2 id=&#34;practices&#34;&gt;Practices&lt;/h2&gt;
&lt;p&gt;For comfortable experience, OBP suggests few things. And, these are the main guideline that we will follow:&lt;br&gt;
(i) distance to focusing object is between 0.75 and 3.5 meters [OBP 10],&lt;br&gt;
(ii) post-processing effects are applied to both eyes [OBP 10],&lt;br&gt;
(iii) use default FOV [OBP 13],&lt;br&gt;
(iv) Viewing the environment from a stationary position is most comfortable. [OBP 6] Users will mostly be standing in a training-stage, and evaluation stage in a game form would also mostly be in a stationary position.&lt;/p&gt;
&lt;h3 id=&#34;exceptions&#34;&gt;Exceptions&lt;/h3&gt;
&lt;p&gt;In case of having the network visualized as extra work, there may be a possibility of having frame-rate drops. But, this is only if we do the extra work.&lt;/p&gt;
&lt;h2 id=&#34;2-qlearning-agents-playing-each-other&#34;&gt;2 Q-Learning Agents Playing each other&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/sqJ12PzacdU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This project was advised by Prof. &lt;a href=&#34;https://cs.illinois.edu/directory/profile/shaffer1&#34;&gt;Eric Shaffer&lt;/a&gt;, and supervised by &lt;a href=&#34;https://www.linkedin.com/in/jonathan-hoelzel&#34;&gt;Jonathan Hoelzel&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI, Physics, and Graphics Programming by Byung Il Choi&lt;/li&gt;
&lt;li&gt;Graphics Programming and Game Play by Seongsu Ha&lt;/li&gt;
&lt;li&gt;User Interface and Graphic Design by Chris Wegenek&lt;/li&gt;
&lt;li&gt;Sound and Testing by Alejandro Marin&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
